{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"..//output//2023-01-29-201405.png\")\n",
    "\n",
    "img = cv2.imread(\"C://Users/e801085/Downloads/image2021-10-6_12-13-33.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    cv2.imshow(\"show_img\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Resizing\n",
    "#img = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "#img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "#img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n",
    "show_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "show_img(gray)\n",
    "#blurred = cv2.GaussianBlur(gray, (7, 7), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.adaptiveThreshold(gray, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "#mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 10)\n",
    "#mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 31, 10)\n",
    "show_img(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel = np.ones((2,2),np.uint8)\n",
    "#processed_img = cv2.erode(mask, kernel, iterations = 1)\n",
    "#processed_img = cv2.dilate(processed_img, kernel, iterations = 1)\n",
    "\n",
    "#show_img(processed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(mask, (3, 3), 0)\n",
    "show_img(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#try to erase images from context \n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # transform to grayscale\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]  # perform OTSU threhold\n",
    "cv2.rectangle(thresh, (0, 0), (w, h), (0, 0, 0), 2)\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]  # search for contours\n",
    "max_cnt = max(contours, key=cv2.contourArea)  # select biggest one\n",
    "mask = np.zeros((h, w), dtype=np.uint8)  # create a black mask\n",
    "cv2.drawContours(mask, [max_cnt], -1, (255, 255, 255), -1)  # draw biggest contour on the mask\n",
    "kernel = np.ones((15, 15), dtype=np.uint8)  # make a kernel with appropriate values - in both cases (resized and original) 15 is ok\n",
    "erosion = cv2.erode(mask, kernel, iterations=1)  # erode the mask with given kernel\n",
    "\n",
    "reverse = cv2.bitwise_not(img.copy())  # reversed image of the actual image 0 becomes 255 and 255 becomes 0\n",
    "processed_img = cv2.bitwise_and(reverse, reverse, mask=erosion)  # per-element bit-wise conjunction of the actual image and eroded mask (erosion)\n",
    "processed_img = cv2.bitwise_not(processed_img) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = blurred.shape\n",
    "cv2.rectangle(blurred, (0, 0), (w, h), (0, 0, 0), 2)\n",
    "contours = cv2.findContours(blurred, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]  # search for contours\n",
    "max_cnt = max(contours, key=cv2.contourArea)\n",
    "mask = np.zeros((h, w), dtype=np.uint8)  # create a black mask\n",
    "\n",
    "cv2.drawContours(mask, [max_cnt], -1, (255, 255, 255), -1)  # draw biggest contour on the mask\n",
    "kernel = np.ones((15, 15), dtype=np.uint8)  # make a kernel with appropriate values - in both cases (resized and original) 15 is ok\n",
    "erosion = cv2.erode(mask, kernel, iterations=1)  # erode the mask with given kernel\n",
    "#kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,3))\n",
    "#erosion = cv2.erode(mask, kernel, iterations=1)  # erode the mask with given kernel\n",
    "#dilate = cv2.dilate(erosion, kernel, iterations=5)\n",
    "\n",
    "reverse = cv2.bitwise_not(blurred.copy())  # reversed image of the actual image 0 becomes 255 and 255 becomes 0\n",
    "processed_img = cv2.bitwise_and(reverse, reverse, mask=erosion)  # per-element bit-wise conjunction of the actual image and eroded mask (erosion)\n",
    "processed_img = cv2.bitwise_not(processed_img) \n",
    "show_img(processed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pytesseract.image_to_string(img, lang='por')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Primeira etapa que consiste na :onstruçâç das\\nbases para o objetivo de uma arquitetuda\\nrobusta para suportar todo o downsizing de\\nMainframe. Definição e construção da\\narquitetura de referência.\\n\\nv\\n\\nVisão 360\\n\\nEnquadrada na iniciativa que visa o offloading\\nmassivo de dados e a construção de\\n“primitivas' para cada domínio/tabela para\\npotenciar, seja em tempo ou custo, os novos\\ndesenvolvimentos, a iniciativa 'Visão 360'\\npermitirá ter uma visão 360 de cliente,\\ncontrato e produto, potenciando a sua\\nexploração seja para consultas Operacionais\\nou analíticas.\\n\\nIniciativa imediata de refazer as operativas\\nmais executadas / consumistas, com objetivo\\nclaro de redução de custos e evitar aumentos\\n\\nde capacidade ou quebras de serviço. É\\nfundamental nesta iniciativa a divisão\\n(modelização) como principio, potenciando a\\nreutilização em novas peças/funcionalidades.\\n\\nLean Core\\n\\nNova Arquitectura Digital, construida com as\\nnovas a stack tecnológica mais digitaç,\\nexpostas ao mundo e a novos negócios. Nova\\nAplicação de Cartões e do centro de\\nAutorizações no novo Core-Banking.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dução\\nIntrodução\\n\\nprecisamos mesmo de outro livro sobre dietas? Não, Apesar\\ndo título, a Dieta Pegan não é uma dieta — é antes um con\\n\\njunto de princípios simples que misturam Ciência e bom\\nsenso em diretrizes que promovem a saúde, a perda de peso\\ne a longevidade, e que podem ser facilmente adaptados a\\nqualquer preferência filosófica ou cultural. O Que sabemos\\nsobre a alimentação? De onde vem esse conhecimento?\\nQue conclusões podemos tirar dos dados existentes? Como\\npodemos combinar tudo isso com preferências dietéticas,\\nfilosóficas, sociais e culturais? Como médico na linha da\\nfrente da epidemia das doenças crónicas é da obesidade\\n(um médico que usa os alimentos como Principal medica-\\nmento no tratamento de doenças e na otimização da saúde\\nhá 30 anos), entristecem-me as guerras dietéticas e as dietas\\n\\nda moda. Política, religião e nutrição são áreas igualmente\\npolarizadoras.\\n\\nA Dieta Pegan começou como uma piada. Há vários\\nanos, integrei um painel de nutrição numa palestra de dois\\namigos — um médico defensor da dieta paleo e um cardio-\\nlogista vegan. Ambos defenderam vigorosamente os seus\\n\\npontos de vista. Para quebrar a tensão, eu disse em tom\\nde brincadeira: «Bem, se um de vocês é paleo e o outro é\\nvegan, então devo ser Pegan.» E foi assim que tudo começou.\\n'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1214\n"
     ]
    }
   ],
   "source": [
    "ret, mask = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)\n",
    "image_final = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "ret, new_img = cv2.threshold(image_final, 180, 255, cv2.THRESH_BINARY)  # for black text , cv.THRESH_BINARY_INV\n",
    "'''\n",
    "        line  8 to 12  : Remove noisy portion \n",
    "'''\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,\n",
    "                                                        3))  # to manipulate the orientation of dilution , large x means horizonatally dilating  more, large y means vertically dilating more\n",
    "dilated = cv2.dilate(new_img, kernel, iterations=9)  # dilate , more the iteration more the dilation\n",
    "\n",
    "# Find contours and filter using aspect ratio\n",
    "# Remove non-text contours by filling in the contour\n",
    "#cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cnts = contours[0] #if len(contours) == 2 else contours[1]\n",
    "print(len(cnts))\n",
    "for c in cnts:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    ar = w / float(h)\n",
    "    if ar < 5:\n",
    "        #cv2.drawContours(dilated, [c], -1, (0,0,0), -1)\n",
    "        cv2.drawContours(mask, [c], -1, (0, 255, 0), -1)\n",
    "\n",
    "# Bitwise dilated image with mask, invert, then OCR\n",
    "#result = 255 - cv2.bitwise_and(dilated, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(dilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"..//output//2023-01-29-201405.png\")\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "#_,thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "_,thresh = cv2.threshold(gray,200,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#contours, _ = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "cnt = contours[0]\n",
    "x,y,w,h = cv2.boundingRect(cnt)\n",
    "#print(x,y,w,h)\n",
    "#crop = image[y:y+h,x:x+w]\n",
    "#show_img(image)\n",
    "#show_img(crop)\n",
    "\n",
    "result = cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,0), 10)\n",
    "show_img(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1920 1080\n"
     ]
    }
   ],
   "source": [
    "contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnt = contours[0]\n",
    "x,y,w,h = cv2.boundingRect(cnt)\n",
    "print(x,y, w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = image[y:y+h,x:x+w]\n",
    "show_img(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"..//output//2023-01-29-201305.png\")\n",
    "show_img(image)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#performing binary thresholding\n",
    "kernel_size = 3\n",
    "ret,thresh = cv2.threshold(gray,200,255,cv2.THRESH_BINARY)  \n",
    "\n",
    "#finding contours \n",
    "#cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "#drawing Contours\n",
    "radius =2\n",
    "color = (30,255,50)\n",
    "cv2.drawContours(image, cnts, -1,color , radius)\n",
    "show_img(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(935, 1) (1776, 1083)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"..//output//2023-01-29-201305.png\")\n",
    "#image = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "show_img(image)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#performing binary thresholding\n",
    "kernel_size = 3\n",
    "ret,thresh = cv2.threshold(gray,200,255,cv2.THRESH_BINARY)  \n",
    "\n",
    "#finding contours \n",
    "#cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "min_x = 20000\n",
    "max_x = 0\n",
    "min_y = 20000\n",
    "max_y = 0\n",
    "start_point = (0,0)\n",
    "end_point = (0,0)\n",
    "for contour in cnts:\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area > 1:\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        if x < min_x:\n",
    "            min_x = x+1\n",
    "        if x+10 > max_x:\n",
    "            max_x = x+10+1\n",
    "        if y < min_y:\n",
    "            min_y = y+1\n",
    "        if y+10 > max_y:\n",
    "            max_y = y+10+1\n",
    "start_point = (min_x, min_y)\n",
    "end_point = (max_x, max_y)\n",
    "print(start_point, end_point)\n",
    "#drawing Contours\n",
    "radius =2\n",
    "color = (30,255,50)\n",
    "#cv2.drawContours(image, cnts, -1,color , radius)\n",
    "show_img(image)\n",
    "\n",
    "cropped_image = image[min_y:max_y, min_x:max_x]\n",
    "show_img(cropped_image)\n",
    "\n",
    "\n",
    "#result = cv2.rectangle(image, start_point, end_point, (0,255,0), 1)\n",
    "#show_img(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 1920\n",
      "1080 1920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8213541666666667"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h,w,_ = image.shape\n",
    "print(h,w)\n",
    "\n",
    "c_h,c_w,_ = cropped_image.shape\n",
    "print(h,w)\n",
    "c_w/w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc7726f85f61331e6dd0cea756754f6cae0aaa43736a6d1e1ed712773b9047bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
